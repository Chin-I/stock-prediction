{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution1D, Convolution2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "from random import randint\n",
    "from keras.layers import Merge, LSTM, Dense\n",
    "# Features: ['Adj_Close', 'Close', 'Date', 'High', 'Low', 'Open', 'Symbol', 'Volume']\n",
    "testData = np.genfromtxt('testData.txt', dtype = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-589411eb971f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X4' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 1  \n",
    "# One single featuere - Yahoo's highPrice\n",
    "# Output - Yahoo's highPrice\n",
    "# \n",
    "for tuple in testData:\n",
    "    X4.append(tuple[4])\n",
    "\n",
    "size = 1000\n",
    "window = 25\n",
    "X = np.empty([0, window])\n",
    "Y = np.zeros(size)\n",
    "batchSize = 10\n",
    "\n",
    "for i in range(size):\n",
    "    start = randint(0, len(testData)-window-1)\n",
    "    X = np.concatenate((X, np.asarray(X4[start : start + window]).reshape(1, window)), axis = 0)\n",
    "    Y[i] = X4[start + window]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = window))\n",
    "model.compile(optimizer='rmsprop',loss='mse') # for a mean squared error regression problem\n",
    "history = model.fit(X, Y, validation_split=0.33, batch_size=batchSize, nb_epoch=20, initial_epoch=0)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.axis((0, 20, 0, 50))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_loss = model.evaluate(X, Y, batch_size=batchSize, verbose=1)\n",
    "print(\"\\nMSE: {}\".format(training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scope = 20  # should be smaller than len(Y)\n",
    "YHat = model.predict(X, batch_size=batchSize, verbose=0)\n",
    "YHat = np.ravel(YHat)\n",
    "x = np.arange(0, scope)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(x, Y[0:scope], 'b', x, YHat[0:scope], 'r')\n",
    "plt.show()\n",
    "training_loss = model.evaluate(X, Y, batch_size=batchSize, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution1D, Convolution2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from random import randint\n",
    "from keras.layers import Merge, LSTM, Dense\n",
    "np.random.seed(7) # fix random seed to ensure the results are reproducible\n",
    "\n",
    "# Features: ['Adj_Close', 'Close', 'Date', 'High', 'Low', 'Open', 'Symbol', 'Volume']\n",
    "testData = np.genfromtxt('testData.txt', dtype = None)\n",
    "\n",
    "# make feature 2 - dates to be number comvertable\n",
    "for tuple in testData:\n",
    "    tuple[2] = tuple[2].replace(\"-\", \"\")\n",
    "    \n",
    "# convert feature 6 - stock name to be stock-id (Yahoo == 1)\n",
    "for tuple in testData:\n",
    "    tuple[6] = 1\n",
    "\n",
    "# 7 features so far\n",
    "data = [[], [], [], [], [], [], []]  \n",
    "for tuple in testData:\n",
    "    for i in range(len(data)):\n",
    "            data[i].append(float(tuple[i]))\n",
    "# Weights adjustment\n",
    "w = [0.01, 0.01, 10e-9, 1, 0.01, 0.01, 0, 10e-6]\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        data[i][j] = data[i][j] * w[i]\n",
    "\n",
    "# Remove redunt features\n",
    "# Features: ['Adj_Close', 'Close', 'Date', 'High', 'Low', 'Open', 'Symbol', 'Volume']\n",
    "f = [0, 1, 2, 3, 4, 5]\n",
    "temp = []\n",
    "for i in f:\n",
    "    temp.append(data[i])\n",
    "data = temp\n",
    "            \n",
    "# convert data into numpy 2d array\n",
    "data = np.asarray(data)   \n",
    "\n",
    "# print(data[2])\n",
    "\n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 1000\n",
    "window = 40\n",
    "batchSize = 50\n",
    "# Three dim\n",
    "# dim1: each datum\n",
    "# dim2: TimeStep: a sequence of consecutive values \n",
    "# dim3: Feature Dimention: There are 7 features\n",
    "X = np.empty([0, window, len(data)])  \n",
    "Y = np.zeros(size)\n",
    "\n",
    "\n",
    "# print(data.shape)\n",
    "# print(X.shape)\n",
    "# print(data[:, 0:0 + window].shape)\n",
    "for i in range(size):\n",
    "    start = randint(0, len(testData)-window-1)\n",
    "    oneSlice = data[:, start:start + window].T\n",
    "    # to concatenate, we need to reshape one slice to 3d\n",
    "    X = np.concatenate((X, np.asarray(oneSlice).reshape(1, window, len(data))), axis = 0) \n",
    "    Y[i] = data[3][start + window]    # Need to figure out which is high \n",
    "# X = X.reshape(len(X), len(data)*window)\n",
    "# print(X)\n",
    "# print(Y)\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mse = 6.9\n",
    "# model.add(Convolution1D(len(data), window*0.5, border_mode='same', input_shape=(window, len(data))))\n",
    "# model.add(LSTM(int(p*0.8), input_shape=(window, len(data))))\n",
    "# model.add(Dense(p*0.6))\n",
    "# model.add(Dense(p*0.3))\n",
    "# model.add(Dense(p*0.1))\n",
    "# model.add(Dense(3))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# mse = 2.8\n",
    "# p = window*len(data)\n",
    "# model.add(Convolution1D(len(data), window*0.1, border_mode='same', input_shape=(window, len(data))))\n",
    "# model.add(LSTM(int(p*0.3), input_shape=(window, len(data))))\n",
    "# model.add(Dense(p*0.1))\n",
    "# model.add(Dense(p*0.08))\n",
    "# model.add(Dense(3))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# mse = 1.6 - Test, 0.9 - Validation\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(120, input_shape=(window, len(data))))\n",
    "# model.add(Dense(100))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='rmsprop',loss='mse') # a mean squared error regression problem\n",
    "# history = model.fit(X, Y, validation_split=0.33, batch_size=batchSize, nb_epoch=20, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Convolution1D(len(data), window*0.1, border_mode='same', input_shape=(window, len(data))))\n",
    "# model.add(LSTM(int(size*0.5), input_shape=(window, len(data))))\n",
    "# model.add(Dense(p*0.8, activation = \"linear\"))\n",
    "# model.add(Dense(p*0.5, activation = \"linear\"))\n",
    "# model.add(Dense(1, input_shape=(window, len(data))))\n",
    "model.add(LSTM(120, input_shape=(window, len(data))))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='rmsprop',loss='mse') # a mean squared error regression problem\n",
    "history = model.fit(X, Y, validation_split=0.4, batch_size=batchSize, nb_epoch=20, initial_epoch=0)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.axis((0, 50, 0, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_loss = model.evaluate(X, Y, batch_size=batchSize, verbose=1)\n",
    "print(\"\\nMSE: {}\".format(training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scope = 160  # should be smaller than len(Y)\n",
    "YHat = model.predict(X, batch_size=batchSize, verbose=0)\n",
    "YHat = np.ravel(YHat)\n",
    "x = np.arange(0, scope)\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(x, Y[0:scope], 'b', x, YHat[0:scope], 'r')\n",
    "plt.title(\"Red - Prediction, Blue - Real Value\")\n",
    "plt.show()\n",
    "# training_loss = model.evaluate(X, Y, batch_size=batchSize, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# LSTM tuning\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution1D, Convolution2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.layers import Merge, LSTM, Dense \n",
    "np.random.seed(7) # fix random seed to ensure the results are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reference from : http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "# dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-Open', 'YHOO-High', 'YHOO-Low', 'YHOO-Close', 'YHOO-Adj_Close', 'YHOO-Volume'])\n",
    "dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-High'])\n",
    "dataset = dataframe.values\n",
    "# reverse the dataset by row, oldest date first\n",
    "dataset = np.flip(dataset, 0) \n",
    "dataset.astype('float32')\n",
    "# plot the dataset\n",
    "plt.title('Yahoo HighPrice - Date')\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "# normalization\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split training and test sets\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_ordered_dataset(dataset, look_back = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "# reshape training and test set into X = t, Y = t + 1\n",
    "look_back = 20\n",
    "trainX, trainY = create_ordered_dataset(train, look_back)\n",
    "testX, testY = create_ordered_dataset(test, look_back)\n",
    "# print(trainX[0:5])\n",
    "# print(trainY[0:5])\n",
    "# transform data into [dim1 - samples, dim2 - time steps, dim3 - features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# print(trainX[0:5])\n",
    "# print(trainX.shape)\n",
    "# create training network\n",
    "# Reference: Which optimizer to use\n",
    "# http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_dim = look_back))\n",
    "model.add(Dense(40))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit(trainX, trainY, batch_size=2, nb_epoch=50, verbose = 2, validation_split=0.1)\n",
    "# Reference for parameters: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.axis((0, 50, 0, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# denormalization\n",
    "# trainPredict = scaler.inverse_transform(trainPredict)\n",
    "# trainY = scaler.inverse_transform(trainY)\n",
    "# testPredict = scaler.inverse_transform(testPredict)\n",
    "# testY = scaler.inverse_transform(testY)\n",
    "\n",
    "# MSE\n",
    "trainScore = mean_squared_error(trainY, trainPredict[:, 0])\n",
    "testScore = mean_squared_error(testY, testPredict[:, 0])\n",
    "print('Training MSE: {}'.format(trainScore))\n",
    "print(\"Test MSE: {}\".format(testScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:(len(trainPredict)+look_back), :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[(len(trainPredict)+(look_back*2)):(len(dataset)), :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize = (40,20))\n",
    "# plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(dataset)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 1, One Feature, Random window, Dense only but with multiple layers\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution1D, Convolution2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.layers import Merge, LSTM, Dense \n",
    "np.random.seed(7) # fix random seed to ensure the results are reproducible\n",
    "\n",
    "# reference from : http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "# dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-Open', 'YHOO-High', 'YHOO-Low', 'YHOO-Close', 'YHOO-Adj_Close', 'YHOO-Volume'])\n",
    "dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-High'])\n",
    "dataset = dataframe.values\n",
    "# reverse the dataset by row, oldest date first\n",
    "dataset = np.flip(dataset, 0) \n",
    "dataset.astype('float32')\n",
    "\n",
    "# plot the dataset\n",
    "# plt.title('Yahoo HighPrice - Date')\n",
    "# plt.plot(dataset)\n",
    "# plt.show()\n",
    "\n",
    "# normalization\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split training and test sets\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_random_dataset(dataset, look_back = 1, iteration_time = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(iteration_time):\n",
    "        start = randint(0, len(dataset)-look_back-1) # randint(a,b), a <= x <= b\n",
    "        a = dataset[start:(start+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[start+look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def create_ordered_dataset(dataset, look_back = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# reshape training and test set into X = t, Y = t + 1\n",
    "look_back = 20\n",
    "iteration_time = 2000\n",
    "trainX, trainY = create_random_dataset(train, look_back, iteration_time)\n",
    "testX, testY = create_random_dataset(test, look_back, 5)\n",
    "orderedX, orderedY = create_ordered_dataset(dataset, look_back) # this is used for trend evaluation\n",
    "\n",
    "# transform data into two dim input. Since it's already 2d, this part is useless. \n",
    "# If more features are used, we need this part to increase the dimension\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1]))\n",
    "orderedX = np.reshape(orderedX, (orderedX.shape[0], orderedX.shape[1]))\n",
    "# print(trainX[0:5])\n",
    "# print(trainY.shape)\n",
    "\n",
    "# # create training network\n",
    "# # Reference: Which optimizer to use\n",
    "# # http://sebastianruder.com/optimizing-gradient-descent/index.html #rmsprop\n",
    "batchSize = 2\n",
    "epoch = 30\n",
    "print(\"Begin\")\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_shape=(look_back,)))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='rmsprop',loss='mse') # can try optimizer = 'adam'\n",
    "history = model.fit(trainX, trainY, validation_split=0.05, batch_size=batchSize, nb_epoch=epoch, initial_epoch=0, verbose = 1)\n",
    "print(\"Finish\")\n",
    "\n",
    "# Evaluation on MSE\n",
    "    # With current parameter\n",
    "    # MSE on trainX: 0.429521106769, MSE on testX: 0.610605459544\n",
    "    # Graph of training and test mse, here training and test data are all in trainX\n",
    "plt.axis((0, epoch, 0, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "    # MSE on trainX and testX   \n",
    "training_loss = model.evaluate(trainX, trainY, batch_size=batchSize, verbose = 1)\n",
    "print(\"\\nMSE on trainX: {}\".format(training_loss))\n",
    "test_loss = model.evaluate(testX, testY, batch_size=batchSize, verbose = 1)\n",
    "print(\"\\nMSE on testX: {}\".format(test_loss))\n",
    "\n",
    "# Evaluation on Trend\n",
    "orderedYHat = model.predict(orderedX, batch_size = batchSize, verbose = 0);\n",
    "# The YHat has one day delay compared with Y, that's the reason for previous bad performance\n",
    "def evaluateY(Y, YHat):\n",
    "    total = len(YHat)\n",
    "    count = 0\n",
    "    for i in range(1, total-1):\n",
    "        if (YHat[i+1] - YHat[i]) * (Y[i] - Y[i-1]) > 0:\n",
    "            count += 1\n",
    "    print(\"Trend prediction performance: {}%\".format(count * 100.0 / total))\n",
    "print('Overall:')\n",
    "evaluateY(orderedY, orderedYHat)    \n",
    "print('Test Set Only:')\n",
    "evaluateY(orderedY[train_size:], orderedYHat[train_size:])  \n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.plot(orderedY)\n",
    "plt.plot(orderedYHat, c = 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# LSTM tuning\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution1D, Convolution2D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.layers import Merge, LSTM, Dense \n",
    "np.random.seed(7) # fix random seed to ensure the results are reproducible\n",
    "\n",
    "# reference from : http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "# dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-Open', 'YHOO-High', 'YHOO-Low', 'YHOO-Close', 'YHOO-Adj_Close', 'YHOO-Volume'])\n",
    "dataframe = pandas.read_csv('Yahoo+Nasdaq+SP500+DJ30-20100101-20161231.csv', usecols=['YHOO-Open', 'YHOO-High', 'YHOO-Low', 'YHOO-Close', 'YHOO-Adj_Close', 'YHOO-Volume'])\n",
    "dataset = dataframe.values\n",
    "# reverse the dataset by row, oldest date first\n",
    "dataset = np.flip(dataset, 0) \n",
    "dataset.astype('float32')\n",
    "# plot the dataset\n",
    "plt.title('Yahoo HighPrice - Date')\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "# normalization\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split training and test sets\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_ordered_dataset(dataset, look_back = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "# reshape training and test set into X = t, Y = t + 1\n",
    "look_back = 20\n",
    "trainX, trainY = create_ordered_dataset(train, look_back)\n",
    "testX, testY = create_ordered_dataset(test, look_back)\n",
    "# print(trainX[0:5])\n",
    "# print(trainY[0:5])\n",
    "# transform data into [dim1 - samples, dim2 - time steps, dim3 - features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# print(trainX[0:5])\n",
    "# print(trainX.shape)\n",
    "# create training network\n",
    "# Reference: Which optimizer to use\n",
    "# http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_dim = look_back))\n",
    "model.add(Dense(40))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit(trainX, trainY, batch_size=2, nb_epoch=50, verbose = 2, validation_split=0.1)\n",
    "# Reference for parameters: https://keras.io/models/sequential/\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
